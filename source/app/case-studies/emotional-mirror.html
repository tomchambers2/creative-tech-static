<section>
	<h2>Emotional Mirror</h2>

	VIDEO

	<h3>Concept</h3>
	<p>What you see is coloured by how you feel. The Emotional Mirror brings you face to face with this phenomenon by analysing your facial expression and reflecting it back to you. Along with your own image it displays your thoughts as tweets that embody the emotion you’re experiencing. While you’re looking into the mirror the feedback loop between sensation and perception becomes more visible.</p>

	PICTURE

	<p>Emotional Mirror was first presented at the <a href="http://2016.adaf.gr/event/emotional-mirror/">Athens Digital Art Festival</a> held in May 2016.</p>

	PICTURE

	<h3>Technical</h3>
	<p>The installation uses computer vision to track the expression of the person standing in front and then searches twitter while applying sentiment analysis, scoring tweets from around the world on various emotional properties. It then presents tweets of an appropriate tone, popping up as clouds that appear around the user's head and then float away.</p>

	<p>The project was created using python, C++ and openFrameworks making use of the <a href="https://github.com/kylemcdonald/ofxFaceTracker">ofxFaceTracker addon</a> by <a href="http://kylemcdonald.net/">Kyle MacDonald</a>. The source for <a href="http://github.com/random-quark/emotional-mirror-frontend" target="_blank">the display</a> and the <a href="http://github.com/random-quark/emotional-mirror-backend" target="_blank">tweet analyser backend</a> can be found on our github.</p>

	MORE PICTURES

	<h3>Collaborators</h3>
	<p>We worked with <a href="http://www.michelepanegrossi.com/">Michele Panegrossi</a> and <a href="http://laurapedroni.com/">Laura Pedroni</a> who assisted with the hardware and conceptual design.</p>
</section>
